{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Input.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   URL_ID  114 non-null    int64 \n",
      " 1   URL     114 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\HP-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords_word = stopwords.words(\"english\")\n",
    "punctuation_word = punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3        40  https://insights.blackcoffer.com/will-machine-...\n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..      ...                                                ...\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110     147  https://insights.blackcoffer.com/the-future-of...\n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112     149  https://insights.blackcoffer.com/business-anal...\n",
       "113     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in df['URL']:\n",
    "    print(url)\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    r = session.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    if (len(soup.find_all(\"body\", class_=\"error404\")) == 0):\n",
    "        article = soup.find(\"article\")\n",
    "        article_title = article.find(\"h1\")\n",
    "        article_text = article.find_all(\"p\")\n",
    "        para = []\n",
    "        for paragraph in article_text:\n",
    "            para.append(paragraph.text)\n",
    "        user_id = df[df[\"URL\"] == url][\"URL_ID\"]\n",
    "        obj = open(str(user_id.values[0])+\".txt\", 'w', errors=\"ignore\")\n",
    "        obj.write(article_title.string+\"\\n\")\n",
    "        obj.writelines(para)\n",
    "    else:\n",
    "        user_id = df[df[\"URL\"] == url][\"URL_ID\"]\n",
    "        obj = open(str(user_id.values[0])+\".txt\", 'w', errors=\"ignore\")\n",
    "        obj.write(\"404error\\n\")\n",
    "\n",
    "    # print(para[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text analysis\n",
    "# sentiment analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    vovel=\"AEIOUaeiou\"\n",
    "    vovel_count=0\n",
    "    complex=-1\n",
    "    for A in word:\n",
    "        if A in vovel:\n",
    "            vovel_count+=1\n",
    "    if(word[-1:-3:-1]==\"se\" or word[-1:-3:-1]==\"de\"):\n",
    "        vovel_count-=1\n",
    "    if(vovel_count>2):\n",
    "        complex=1\n",
    "    return(vovel_count,complex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(text):\n",
    "  \"\"\"Counts the number of personal pronouns in a text.\n",
    "\n",
    "  Args:\n",
    "    text: The text to be analyzed.\n",
    "\n",
    "  Returns:\n",
    "    The number of personal pronouns in the text.\n",
    "  \"\"\"\n",
    "\n",
    "  pronouns = re.findall(r\"(I|we|my|ours|us)[^US]\", text)\n",
    "  return len(pronouns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.090559</td>\n",
       "      <td>36.849057</td>\n",
       "      <td>0.562620</td>\n",
       "      <td>21.425048</td>\n",
       "      <td>36.849057</td>\n",
       "      <td>584</td>\n",
       "      <td>1167</td>\n",
       "      <td>3.614644</td>\n",
       "      <td>94</td>\n",
       "      <td>5.282130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.134417</td>\n",
       "      <td>23.808824</td>\n",
       "      <td>0.432792</td>\n",
       "      <td>27.373117</td>\n",
       "      <td>23.808824</td>\n",
       "      <td>293</td>\n",
       "      <td>809</td>\n",
       "      <td>3.748892</td>\n",
       "      <td>68</td>\n",
       "      <td>4.346510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.107609</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>27.421739</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>510</td>\n",
       "      <td>1032</td>\n",
       "      <td>3.722826</td>\n",
       "      <td>87</td>\n",
       "      <td>5.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.103121</td>\n",
       "      <td>22.855263</td>\n",
       "      <td>0.468114</td>\n",
       "      <td>30.587246</td>\n",
       "      <td>22.855263</td>\n",
       "      <td>345</td>\n",
       "      <td>924</td>\n",
       "      <td>3.986431</td>\n",
       "      <td>120</td>\n",
       "      <td>4.516983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.076582</td>\n",
       "      <td>28.552239</td>\n",
       "      <td>0.437292</td>\n",
       "      <td>26.974917</td>\n",
       "      <td>28.552239</td>\n",
       "      <td>394</td>\n",
       "      <td>1028</td>\n",
       "      <td>3.507214</td>\n",
       "      <td>93</td>\n",
       "      <td>4.626242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  URL_ID  \\\n",
       "0             0           0      37   \n",
       "1             1           1      38   \n",
       "2             2           2      39   \n",
       "3             3           3      40   \n",
       "4             4           4      41   \n",
       "\n",
       "                                                 URL  POSITIVE SCORE  \\\n",
       "0  https://insights.blackcoffer.com/ai-in-healthc...              63   \n",
       "1  https://insights.blackcoffer.com/what-if-the-c...              55   \n",
       "2  https://insights.blackcoffer.com/what-jobs-wil...              65   \n",
       "3  https://insights.blackcoffer.com/will-machine-...              55   \n",
       "4  https://insights.blackcoffer.com/will-ai-repla...              47   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              31        0.340426            0.090559            36.849057   \n",
       "1              36        0.208791            0.134417            23.808824   \n",
       "2              34        0.313131            0.107609            27.500000   \n",
       "3              21        0.447368            0.103121            22.855263   \n",
       "4              22        0.362319            0.076582            28.552239   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                     0.562620  21.425048                         36.849057   \n",
       "1                     0.432792  27.373117                         23.808824   \n",
       "2                     0.554348  27.421739                         27.500000   \n",
       "3                     0.468114  30.587246                         22.855263   \n",
       "4                     0.437292  26.974917                         28.552239   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 584        1167           3.614644                 94   \n",
       "1                 293         809           3.748892                 68   \n",
       "2                 510        1032           3.722826                 87   \n",
       "3                 345         924           3.986431                120   \n",
       "4                 394        1028           3.507214                 93   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         5.282130  \n",
       "1         4.346510  \n",
       "2         5.001070  \n",
       "3         4.516983  \n",
       "4         4.626242  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputfile = pd.read_excel('Output Data Structure.xlsx')\n",
    "outputfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in df[\"URL_ID\"]:\n",
    "    obj = open(str(file)+\".txt\", \"r\")\n",
    "    text = obj.read()\n",
    "    # print(text)\n",
    "    token = word_tokenize(text)\n",
    "    word_size_before = len(token)\n",
    "    # print(token)\n",
    "    # removing the stopwords\n",
    "    StopWords_Auditor = open(\n",
    "        \"StopWords\\StopWords_Auditor.txt\", \"r\", errors=\"ignore\")\n",
    "    auditor_text = StopWords_Auditor.read()\n",
    "    auditor = word_tokenize(auditor_text)\n",
    "    # print(auditor)\n",
    "    filter_token_1 = []\n",
    "    for word in token:\n",
    "        if (word not in auditor):\n",
    "            filter_token_1.append(word)\n",
    "    # print(filter_token_1)\n",
    "\n",
    "    StopWords_Currencies = open(\n",
    "        \"StopWords\\StopWords_Currencies.txt\", \"r\", errors=\"ignore\")\n",
    "    Currencies_text = StopWords_Currencies.read()\n",
    "    Currencies = word_tokenize(Currencies_text)\n",
    "    filter_token_2 = []\n",
    "    for word in filter_token_1:\n",
    "        if (word not in Currencies):\n",
    "            filter_token_2.append(word)\n",
    "\n",
    "    StopWords_DatesandNumbers = open(\n",
    "        \"StopWords\\StopWords_DatesandNumbers.txt\", \"r\")\n",
    "    DatesandNumbers_text = StopWords_DatesandNumbers.read()\n",
    "    DatesandNumbers = word_tokenize(DatesandNumbers_text)\n",
    "    filter_token_3 = []\n",
    "    for word in filter_token_2:\n",
    "        if (word not in DatesandNumbers):\n",
    "            filter_token_3.append(word)\n",
    "\n",
    "    StopWords_Generic = open(\"StopWords\\StopWords_Generic.txt\", \"r\")\n",
    "    Generic_text = StopWords_Generic.read()\n",
    "    Generic = word_tokenize(Generic_text)\n",
    "    filter_token_4 = []\n",
    "    for word in filter_token_3:\n",
    "        if (word not in Generic):\n",
    "            filter_token_4.append(word)\n",
    "\n",
    "    StopWords_GenericLong = open(\"StopWords\\StopWords_GenericLong.txt\", \"r\")\n",
    "    GenericLong_text = StopWords_GenericLong.read()\n",
    "    GenericLong = word_tokenize(GenericLong_text)\n",
    "    filter_token_5 = []\n",
    "    for word in filter_token_4:\n",
    "        if (word not in GenericLong):\n",
    "            filter_token_5.append(word)\n",
    "    # print(filter_token_5)\n",
    "    StopWords_Geographic = open(\"StopWords\\StopWords_Geographic.txt\", \"r\")\n",
    "    Geographic_text = StopWords_Geographic.read()\n",
    "    Geographic = word_tokenize(Geographic_text)\n",
    "    filter_token_6 = []\n",
    "    for word in filter_token_5:\n",
    "        if (word not in Geographic):\n",
    "            filter_token_6.append(word)\n",
    "    # print(filter_token_6)\n",
    "\n",
    "    StopWords_Names = open(\"StopWords\\StopWords_Names.txt\", \"r\")\n",
    "    Names_text = StopWords_Names.read()\n",
    "    Names = word_tokenize(Names_text)\n",
    "    filter_token_7 = []\n",
    "    for word in filter_token_6:\n",
    "        if (word not in Names):\n",
    "            filter_token_7.append(word)\n",
    "    # print(filter_token_7)\n",
    "    word_size_after = len(filter_token_7)\n",
    "    # postive score\n",
    "    positive_score = 0\n",
    "    positive_words = open(\"MasterDictionary\\\\positive-words.txt\", \"r\")\n",
    "    pos_words_text = positive_words.read()\n",
    "    pos_words = word_tokenize(pos_words_text)\n",
    "    for word in filter_token_7:\n",
    "        if (word in pos_words):\n",
    "            positive_score += 1\n",
    "\n",
    "    # print(positive_score)\n",
    "\n",
    "    # Negative Score\n",
    "    Negative_score = 0\n",
    "    Negative_words = open(\"MasterDictionary\\\\negative-words.txt\", \"r\")\n",
    "    Neg_words_text = Negative_words.read()\n",
    "    Neg_words = word_tokenize(Neg_words_text)\n",
    "    for word in filter_token_7:\n",
    "        if (word in Neg_words):\n",
    "            Negative_score += 1\n",
    "\n",
    "    # print(Negative_score)\n",
    "\n",
    "    # Polarity Score\n",
    "    Polarity_Score = (positive_score-Negative_score) /((positive_score+Negative_score)+0.000001)\n",
    "    # print(Polarity_Score)\n",
    "    # Subjectivity Score\n",
    "    Subjectivity_Score = (positive_score + Negative_score) /((word_size_after) + 0.000001)\n",
    "    # print(Subjectivity_Score)\n",
    "\n",
    "    # sentences tokenizer\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    sentence_token = sent_tokenize(text)\n",
    "    sentence_token_size = len(sentence_token)\n",
    "    # print(sentence_token)\n",
    "\n",
    "    # Analysis of Readability\n",
    "    if(sentence_token_size!=0 and word_size_before!=0):\n",
    "        Average_Sentence_Length = word_size_before/sentence_token_size\n",
    "    # print(Average_Sentence_Length)\n",
    "\n",
    "    # we need to find the no of complex world\n",
    "    # we need to find syalbble count for each word\n",
    "    complex_word_count = 0\n",
    "    sum_of_characters = 0\n",
    "    sum_of_syllables = 0\n",
    "    for word in token:\n",
    "        syllables, complex = count_syllables(word)\n",
    "        sum_of_syllables+=syllables\n",
    "        sum_of_characters += len(word)\n",
    "        if (complex == 1):\n",
    "            complex_word_count = complex_word_count+1\n",
    "    if(word_size_after!=0):\n",
    "        Percentage_Complex_words = complex_word_count/word_size_after\n",
    "\n",
    "    if word_size_after !=0 :\n",
    "        avg_syllable_count = sum_of_syllables/word_size_after\n",
    "    # print(Percentage_Complex_words)\n",
    "\n",
    "    # fog index\n",
    "    fog_index = 0.4 * (sentence_token_size + Percentage_Complex_words)\n",
    "    # print(fog_index)\n",
    "\n",
    "    # average no of words per sentence\n",
    "    if sentence_token_size !=0:\n",
    "        avg_no_words_sentence = word_size_before/sentence_token_size\n",
    "    # print(avg_no_words_sentence)\n",
    "\n",
    "    word_count = 0\n",
    "\n",
    "    for word in token:\n",
    "        if (not word in stopwords_word and not word in punctuation_word):\n",
    "            word_count += 1\n",
    "\n",
    "    # Average Word Length\n",
    "    if word_size_before !=0:\n",
    "        Average_Word_Length = sum_of_characters/word_size_before\n",
    "    # print(Average_Word_Length)\n",
    "\n",
    "    # personal pronouns\n",
    "    personal_pros = count_personal_pronouns(text)\n",
    "\n",
    "    outputfile.loc[(outputfile['URL_ID'] == file), ['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
    "                                                    'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
    "                                                    'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
    "                                                    'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "                                                    'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']] = positive_score, Negative_score, Polarity_Score, Subjectivity_Score, Average_Sentence_Length, Percentage_Complex_words, fog_index, avg_no_words_sentence, complex_word_count, word_count, avg_syllable_count, personal_pros, Average_Word_Length\n",
    "\n",
    "    # print(outputfile[outputfile['URL_ID'] == file])\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile.to_excel(\"Output Data Structure.xlsx\", 'sheet3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
